{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GustaveRw/NLP-Fellowship/blob/master/Text_To_Features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text to features\n",
        "This is the process of converting tokens to numbers. This is because the machine only works with numbers. Moreover, for manipulation of text, the tokens need to be in digit form to apply any transformations.\n",
        "\n",
        "The input of the function will be the matrix of tokens and output will be matrix with digits."
      ],
      "metadata": {
        "id": "ogRvOeRI4kHK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simplest form of featurization\n",
        "The simplest way is to assign each unique text a number starting from 0 and increase by one until all the text has been assigned numbers"
      ],
      "metadata": {
        "id": "7fPAtFjX4ibA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "1xFBIupW8mHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c946TeePQRE8",
        "outputId": "d46b2f79-db2f-4369-fa58-548371a20b15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'of': 0, 'a': 1, 'example': 2, 'is': 4, 'this': 6, 'sentences': 7, 'list': 10, 'second': 8, 'sentence': 9, 'in': 11, 'word': 3, 'complexity': 5, 'for': 12}\n"
          ]
        }
      ],
      "source": [
        "# fitting\n",
        "\n",
        "\n",
        "list_sentences = ['this is a list of sentences example', 'second sentence in list of sentence', 'a word for complexity',]\n",
        "all_word = set()\n",
        "word_to_index = {}\n",
        "index_to_word = {}\n",
        "\n",
        "for sent in list_sentences:\n",
        "    #split the sentence into words\n",
        "    for word in sent.split():\n",
        "        # add the words to the set\n",
        "        \n",
        "        all_word.add(word)\n",
        "    \n",
        "    for index,word in enumerate(all_word):\n",
        "        word_to_index[word] = index\n",
        "        index_to_word[index] = word\n",
        "\n",
        "word_to_index\n",
        "print(word_to_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bag Of Words (BoW)\n",
        "* Split the sentences into words\n",
        "* Create a dictionary with all unique words and their indices\n",
        "* Create a vector, size same as the total number of unique words\n",
        "* For every word in a sentence, get the index and add 1. \n",
        "* The result will be a vector for each sentence with length same as all the unique words in all sentences, with frequency of each word in one particular sentence. If a word is not in that sentence, the frequency is 0\n"
      ],
      "metadata": {
        "id": "50_WtShe7PiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_list_words = np.zeros(len(all_word))\n",
        "transformed_list_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHgk8BI8ATf9",
        "outputId": "76b62115-efb6-4f3b-ac0b-83d01bc368e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a vector, size same as the total number of unique words\n",
        "\n",
        "transformed_list_sentences = np.empty((len(list_sentences),len(all_word)))\n",
        "transformed_list_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC6dK9CD6oIc",
        "outputId": "39ddea69-a19a-4fca-866a-7396c638df95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.71251374e-316, 2.33419537e-312, 8.48798317e-313,\n",
              "        2.22809558e-312, 2.46151512e-312, 2.44029516e-312,\n",
              "        2.41907520e-312, 2.14321575e-312, 8.48798317e-313,\n",
              "        2.35541533e-312, 2.12199579e-312],\n",
              "       [2.46151512e-312, 2.01589600e-312, 2.33419537e-312,\n",
              "        2.14321575e-312, 9.76118064e-313, 2.46151512e-312,\n",
              "        2.31297541e-312, 8.48798317e-313, 9.33678148e-313,\n",
              "        2.27053550e-312, 2.56761491e-312],\n",
              "       [2.29175545e-312, 2.31297541e-312, 2.12199579e-312,\n",
              "        6.79038654e-313, 2.46151512e-312, 2.31297541e-312,\n",
              "        6.79038653e-313, 2.46151512e-312, 2.31297541e-312,\n",
              "        1.03977794e-312, 8.70018275e-313]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for row,sentence in enumerate(list_sentences):\n",
        "    #replace row with sentence BoW\n",
        "    \n",
        "    \n",
        "    transformed_list_words = np.zeros(len(all_word))\n",
        "    for word in sentence.split():\n",
        "        if word in all_word:\n",
        "            #get the index of the word\n",
        "            word_index = word_to_index[word]\n",
        "            #increase the value by 1\n",
        "            transformed_list_words[word_index]+=1\n",
        "            #print(transformed_list_words)\n",
        "\n",
        "    transformed_list_sentences[row] =  transformed_list_words\n",
        "\n",
        "print(dict(sorted(word_to_index.items(), key=lambda item: item[1])))\n",
        "transformed_list_sentences\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2FAvxz58tdT",
        "outputId": "8e30701f-6844-4f68-b999-ef2156001cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'of': 0, 'a': 1, 'word': 2, 'complexity': 3, 'is': 4, 'this': 5, 'sentences': 6, 'second': 7, 'list': 8, 'in': 9, 'for': 10}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 2., 1., 1., 1., 0.],\n",
              "       [0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = 'this is an example of sentence with sentence that are complexity with many example'\n",
        "transformed_list_words = np.zeros(len(all_word))\n",
        "for word in test_sentence.split():\n",
        "    if word in all_word:\n",
        "        #get the index of the word\n",
        "        word_index = word_to_index[word]\n",
        "        #increase the value by 1\n",
        "        transformed_list_words[word_index]+=1\n",
        "        #print(transformed_list_words)\n",
        "transformed_list_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Fvt-uF0-L80",
        "outputId": "4ab505b9-4e33-4715-8861-67fbea1eddb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 2., 0., 1., 1., 1., 0., 0., 2., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In-class Practicals\n",
        "\n",
        "Convert this into a class and functions:\n"
      ],
      "metadata": {
        "id": "KcGCl8LTEiZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Bow:\n",
        "    def __init__(self):\n",
        "        # Enter code here\n",
        "\n",
        "\n",
        "    def fit(self,document):\n",
        "        \n",
        "        #Enter code \n",
        "        \n",
        "\n",
        "    def transform(self,data):\n",
        "        \n",
        "        #Enter code \n",
        "        return transformed\n",
        "\n",
        "    def fit_transform(self,data):\n",
        "        self.fit(data)\n",
        "\n",
        "        return self.transform(data)\n",
        "\n",
        "    def _transform_single(self,list_words):\n",
        "\n",
        "       # This code is for transforming a single sentence\n",
        "\n",
        "        return transformed"
      ],
      "metadata": {
        "id": "kIl-wPg9RZq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment\n",
        "BOW using your tokens and share some sentences to text"
      ],
      "metadata": {
        "id": "KESkmMIaLCJY"
      }
    }
  ]
}